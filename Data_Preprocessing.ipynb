{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d5745-3e94-487c-bbc7-bbc64fc3fb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All stages of Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357145d6-e05a-4b9c-9da0-e97e3c568ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generally all the modules needed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import h5py\n",
    "import numpy as np\n",
    "import optuna\n",
    "import random\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_curve, auc\n",
    "from joblib import Parallel, delayed\n",
    "import cv2\n",
    "import glob\n",
    "from optuna.importance import get_param_importances\n",
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.ndimage import zoom\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5c43a8-011e-4bf9-9d07-4a069100a07b",
   "metadata": {},
   "source": [
    "## Preprocessing of Data\n",
    "For each file a late measure in the exposure was chosed. \n",
    "\n",
    "First reference pixel corrections must be applied to extract the cross hatch pattern. A standard row correction is applied, then a background subtraction of the second measure of the exposure, then a normalization without outliers (cnns typically expect normalized data). Then in the processing the images are divided into 16 patches, and stored in tensors with a label of whether or not they contain cross hatching (along with their image and patch id). Finally, for quick loading in of the data, these tensors are stored in 4 chunks of about 5000 each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff6df8-3828-4369-b7bc-196a41e62e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the functions needed for this\n",
    "def madstat(a, axis=None, keepdims=False, std=False):\n",
    "    \"\"\"\n",
    "    MADSTAT - Robust statistics using median and median absolute deviation\n",
    "\n",
    "    Parameters:  a, array_like\n",
    "                   Calculate the median absolute deviation of these values.\n",
    "                 axis, tuple\n",
    "                   Axis or axes along which the median absolute deviation is\n",
    "                   computed.\n",
    "                 keepdims, bool (optional)\n",
    "                   If this is set to True, the axes which are\n",
    "                   reduced are left in the result as dimensions with\n",
    "                   size one. With this option, the result will\n",
    "                   broadcast correctly against the input array.\n",
    "                 std, bool (optional)\n",
    "                   If set True, then the MAD is multiplied by 1.4826 to\n",
    "                   estimate the standard deviation of normal deviates.\n",
    "    Returns: Median and median absolute deviation. Optionally returns median\n",
    "             and estimated standard deviation.\n",
    "    \"\"\"\n",
    "    # Compute the median and median absolute deviation\n",
    "    median = np.median(a, axis=axis, keepdims=keepdims)\n",
    "    mad = np.median(np.abs(a-median), axis=axis, keepdims=keepdims)\n",
    "\n",
    "    # Estimate std() if requested\n",
    "    if std is True:\n",
    "        mad *= 1.4826\n",
    "\n",
    "    # Done\n",
    "    return(median, mad)\n",
    "\n",
    "def rowcor(D):\n",
    "    \"\"\"\n",
    "        rowcor(D)\n",
    "        Reference correction using only the top four rows of reference pixels.\n",
    "        parameters: D, array\n",
    "                      The input data cube\n",
    "        Returns:    nothing\n",
    "                      This overwrites the input data\n",
    "    \"\"\"\n",
    "    # Get cube dimensions\n",
    "    nz, ny, nx = D.shape\n",
    "    # Definitions\n",
    "    nout = 32       # The WFI uses 32 outputs for full frame readout\n",
    "    w = nx//nout    # Width of each output in pixels\n",
    "    count = 3        # Clip off the best/worse few samples for robust statistics\n",
    "\n",
    "    # Compute first and last image columns for each output\n",
    "    x0 = np.arange(0, nx, w)    # First cols\n",
    "    x1 = x0 + w-1          # Last cols\n",
    "    # Apply reference correction working frame-by-frame and output-by-output\n",
    "    for z in np.arange(nz):\n",
    "        for op in np.arange(nout):\n",
    "            refpix = D[z, 4093:4095, x0[op]:x1[op]]           # Get ref. pixels\n",
    "            refpix = np.sort(refpix.flatten())[count-1:-count+1]    # Trim outliers\n",
    "            mu = np.mean(refpix)                                 # Robust mean\n",
    "            D[z, :, x0[op]:x1[op]] -= mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fce2fa-c87d-48fa-9fe2-cd7727d7cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gabor_filters(image, angles=[68,114, 34, 170], ksize=15, sigma=4.0, lambd=10.0, gamma=0.5):\n",
    "    gabor_outputs = []\n",
    "    for theta in angles:\n",
    "        kernel = cv2.getGaborKernel((ksize, ksize), sigma, np.deg2rad(theta), lambd, gamma, 0, ktype=cv2.CV_32F)\n",
    "        filtered = cv2.filter2D(image, cv2.CV_32F, kernel)\n",
    "        gabor_outputs.append(filtered)\n",
    "    return np.stack(gabor_outputs, axis=0)\n",
    " \n",
    "def preprocess_patch_with_gabor_and_edges(image):\n",
    "    normed_8bit = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    edges = cv2.Canny(normed_8bit, 50, 150).astype(np.float32) / 255.0\n",
    "    gabor_stack = apply_gabor_filters(normed_8bit)\n",
    "    image = 2 * (image - image.min()) / (image.max() - image.min() + 1e-8) - 1\n",
    "    stacked = np.concatenate([\n",
    "        image[np.newaxis, :, :],\n",
    "        edges[np.newaxis, :, :],\n",
    "        gabor_stack\n",
    "    ], axis=0)\n",
    "    return torch.from_numpy(stacked).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b4b03-16b1-4089-ad4c-754b21edf848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV\n",
    "df = pd.read_csv('new_classes.csv', header=None)\n",
    "df = df[df[0].notna() & (df[0].astype(str).str.strip() != '')]\n",
    " \n",
    "# Parse columns\n",
    "labels_raw = df[1].tolist()   # 'y' or 'n'\n",
    "file_paths = df[0].tolist()\n",
    "patch_column = df[2].fillna('').tolist()\n",
    " \n",
    "labels = [1 if l == 'y' else 0 for l in labels_raw]\n",
    "positive_patches = []\n",
    "for entry in patch_column:\n",
    "    if entry == '':\n",
    "        positive_patches.append([])\n",
    "    else:\n",
    "        # Convert \"3;7;12\" â†’ [2, 6, 11]\n",
    "        patches = [int(p.strip()) - 1 for p in str(entry).split(';') if p.strip().isdigit()]\n",
    "        positive_patches.append(patches)\n",
    " \n",
    "# Set up patch cutting\n",
    "NUM_PATCHES = 4\n",
    "PATCH_SIZE = 1024\n",
    "save_dir = \"/explore/nobackup/people/cemeehan/ProcessedPatches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    " \n",
    "def preprocess_and_save_patch(args):\n",
    "    fpath, label, patch_ids, idx = args\n",
    "    try:\n",
    "        with h5py.File(fpath, 'r') as f:\n",
    "            frames = f[\"Frames\"][[1, len(f[\"Frames\"]) - 15], :, :4096].astype(np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {fpath}: {e}\")\n",
    "        return\n",
    " \n",
    "    rowcor(frames)\n",
    "    cds = frames[1] - frames[0]\n",
    "    vmax = np.percentile(cds, 99)\n",
    "    vmin = -vmax\n",
    "    cds = np.clip(cds, vmin, vmax)\n",
    "    cds = 2 * (cds - vmin) / (vmax - vmin) - 1\n",
    " \n",
    "    for i in range(NUM_PATCHES * NUM_PATCHES):\n",
    "        row = i // NUM_PATCHES\n",
    "        col = i % NUM_PATCHES\n",
    "        patch = cds[row*PATCH_SIZE:(row+1)*PATCH_SIZE, col*PATCH_SIZE:(col+1)*PATCH_SIZE]\n",
    "        patch_tensor = torch.from_numpy(patch).unsqueeze(0)  # Shape: 1x1024x1024\n",
    "        patch_tensor = TF.resize(patch_tensor, [512, 512])   # Resize if needed\n",
    " \n",
    "        meta = {\n",
    "            'data': patch_tensor,\n",
    "            'label': torch.tensor([1.0]) if i in patch_ids else torch.tensor([0.0]),\n",
    "            'filename': os.path.basename(fpath),\n",
    "            'patch_id': i\n",
    "        }\n",
    " \n",
    "        torch.save(meta, os.path.join(save_dir, f\"{idx}_{i}.pt\"))\n",
    "\n",
    "# Run in parallel\n",
    "args_list = [(f, l, p, i) for i, (f, l, p) in enumerate(zip(file_paths, labels, positive_patches))]\n",
    "with Pool(min(cpu_count(), 8)) as pool:\n",
    "    pool.map(preprocess_and_save_patch, args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ebac73-9693-4508-b49c-ad5dfdb4915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob.glob('/explore/nobackup/people/cemeehan/PPProcessedPatchesGabor/*.pt'))\n",
    "chunk_size = 5000\n",
    "chunk = []\n",
    "chunk_idx = 0\n",
    " \n",
    "for i, path in enumerate(paths):\n",
    "    img, label, fname, patch_id = torch.load(path)\n",
    "    sample = {\n",
    "        'data': img,\n",
    "        'label': label,\n",
    "        'filename': fname,\n",
    "        'patch_id': patch_id\n",
    "    }\n",
    "    chunk.append(sample)\n",
    " \n",
    "    if (i + 1) % chunk_size == 0 or (i + 1) == len(paths):\n",
    "        # Save this chunk\n",
    "        torch.save(chunk, f'/explore/nobackup/people/cemeehan/chunk_{chunk_idx}.pt')\n",
    "        print(f\"[INFO] Saved chunk {chunk_idx} with {len(chunk)} samples\")\n",
    "        chunk = []  # reset buffer\n",
    "        chunk_idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ilab-pytorch]",
   "language": "python",
   "name": "conda-env-ilab-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
